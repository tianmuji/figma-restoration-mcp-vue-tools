import fs from 'fs/promises';
import path from 'path';
import chalk from 'chalk';
import sharp from 'sharp';
import pixelmatch from 'pixelmatch';
import { PNG } from 'pngjs';
import { ensureDirectory } from '../utils/path-config.js';

export class FigmaCompareTool {
  constructor() {
    this.description = 'Simple Figma component comparison tool: compare screenshots and generate diff.png';
    this.inputSchema = {
      type: 'object',
      properties: {
        componentName: {
          type: 'string',
          description: 'Name of the component to compare'
        },
        projectPath: {
          type: 'string',
          description: 'Path to the Vue project (required)'
        },
        threshold: {
          type: 'number',
          default: 0.1,
          description: 'Comparison threshold (0-1, lower is more strict)'
        },
        outputPath: {
          type: 'string',
          description: 'Custom output directory for results (optional). If not provided, defaults to src/components/{componentName}/results'
        }
      },
      required: ['componentName', 'projectPath']
    };
  }

  async execute(args) {
    // éªŒè¯å¿…ä¼ å‚æ•°
    if (!args.componentName) {
      throw new Error('âŒ å‚æ•°é”™è¯¯: componentName æ˜¯å¿…ä¼ å‚æ•°ï¼Œè¯·æä¾›ç»„ä»¶åç§°');
    }

    if (!args.projectPath) {
      throw new Error('âŒ å‚æ•°é”™è¯¯: projectPath æ˜¯å¿…ä¼ å‚æ•°ï¼Œè¯·æä¾›é¡¹ç›®è·¯å¾„');
    }

    // éªŒè¯é¡¹ç›®è·¯å¾„æ˜¯å¦å­˜åœ¨
    try {
      await fs.access(args.projectPath);
    } catch (error) {
      throw new Error(`âŒ é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: ${args.projectPath}`);
    }

    const {
      componentName,
      projectPath,
      threshold = 0.1,
      outputPath
    } = args;

    try {
      console.log(chalk.cyan('ğŸ¯ Figma Component Comparison'));
      console.log(chalk.cyan(`Component: ${componentName}`));
      console.log(chalk.gray('='.repeat(50)));

      const resultsDir = outputPath || path.join(projectPath, 'src', 'components', componentName, 'results');
      await ensureDirectory(resultsDir);

      // Check if actual.png exists
      const actualPath = path.join(resultsDir, 'actual.png');
      try {
        await fs.access(actualPath);
        console.log(chalk.green('âœ… Found existing screenshot: actual.png'));
      } catch (error) {
        throw new Error(`Screenshot not found: ${actualPath}\n\nPlease take a screenshot first using the snapDOM screenshot tool:\n  snapdom_screenshot_vue-figma-tools --componentName ${componentName}`);
      }

      // æ‰§è¡Œå›¾ç‰‡å¯¹æ¯”
      console.log(chalk.blue('ğŸ” Performing image comparison...'));
      const comparisonResult = await this.compareImages({
        resultsDir,
        threshold
      });

      console.log(chalk.green('âœ… Comparison completed successfully!'));
      console.log(chalk.yellow(`ğŸ“Š è¿˜åŸåº¦: ${comparisonResult.matchPercentage.toFixed(2)}%`));
      console.log(chalk.gray(`ğŸ“ Diff image saved: ${comparisonResult.paths.diff}`));

      // Check quality level
      if (comparisonResult.matchPercentage < 98) {
        console.log(chalk.red('ğŸš¨ è¿˜åŸåº¦æœªè¾¾åˆ°98%æ ‡å‡†ï¼'));
      } else {
        console.log(chalk.green('ğŸ‰ æ­å–œï¼å·²è¾¾åˆ°98%è¿˜åŸåº¦æ ‡å‡†ï¼'));
      }

      // ä¿å­˜è¿˜åŸåº¦æ•°æ®åˆ°JSONæ–‡ä»¶
      const comparisonData = {
        matchPercentage: comparisonResult.matchPercentage,
        diffPixels: comparisonResult.diffPixels,
        totalPixels: comparisonResult.totalPixels,
        dimensions: comparisonResult.dimensions,
        timestamp: new Date().toISOString(),
        componentName: componentName,
        // æ–°å¢è¯¦ç»†å·®å¼‚åˆ†ææ•°æ®
        analysis: comparisonResult.analysis
      };
      
      const comparisonDataPath = path.join(resultsDir, 'comparison-data.json');
      await fs.writeFile(comparisonDataPath, JSON.stringify(comparisonData, null, 2));
      console.log(chalk.green(`ğŸ“Š è¿˜åŸåº¦æ•°æ®å·²ä¿å­˜: ${comparisonDataPath}`));

      return {
        success: true,
        componentName,
        matchPercentage: comparisonResult.matchPercentage,
        diffPixels: comparisonResult.diffPixels,
        totalPixels: comparisonResult.totalPixels,
        analysis: comparisonResult.analysis,
        diffImagePath: comparisonResult.paths.diff,
        comparisonDataPath: comparisonDataPath
      };

    } catch (error) {
      console.error(chalk.red('âŒ Comparison failed:'), error.message);
      return {
        success: false,
        error: error.message,
        componentName
      };
    }
  }







  async compareImages({ resultsDir, threshold }) {
    const expectedPath = path.join(resultsDir, 'expected.png');
    const actualPath = path.join(resultsDir, 'actual.png');
    const diffPath = path.join(resultsDir, 'diff.png');

    // Check if expected image exists
    try {
      await fs.access(expectedPath);
    } catch (error) {
      throw new Error(`Expected image not found: ${expectedPath}. Please ensure the Figma design image is downloaded.`);
    }

    // Ensure actual image is in correct format and size
    await this.normalizeImage(actualPath, expectedPath);

    // Load images
    const expectedBuffer = await fs.readFile(expectedPath);
    const actualBuffer = await fs.readFile(actualPath);

    const expectedPng = PNG.sync.read(expectedBuffer);
    const actualPng = PNG.sync.read(actualBuffer);

    const { width, height } = expectedPng;
    const diffPng = new PNG({ width, height });

    // Compare images with optimized settings for 3x scale
    console.log(chalk.blue(`ğŸ” Comparing images at ${width} Ã— ${height} resolution...`));

    const diffPixels = pixelmatch(
      expectedPng.data,
      actualPng.data,
      diffPng.data,
      width,
      height,
      {
        threshold: threshold * 1.2, // æé«˜é˜ˆå€¼ä»¥å¿½ç•¥æ›´å¤šæ–‡æœ¬æ¸²æŸ“å·®å¼‚
        includeAA: false, // å¿½ç•¥æŠ—é”¯é½¿åƒç´ å·®å¼‚ï¼Œå‡å°‘æ–‡æœ¬æ¸²æŸ“å·®å¼‚
        alpha: 0.1, // æé«˜alphaå€¼ä»¥å‡å°‘ç»†å¾®å·®å¼‚çš„å½±å“
        aaColor: [255, 255, 0], // Yellow for anti-aliasing differences
        diffColor: [255, 0, 0], // Red for significant differences
        diffColorAlt: [255, 128, 0] // Orange for alternative differences
      }
    );

    // Save diff image
    await fs.writeFile(diffPath, PNG.sync.write(diffPng));

    const totalPixels = width * height;
    const matchPercentage = ((totalPixels - diffPixels) / totalPixels) * 100;

    // æ‰§è¡Œè¯¦ç»†çš„å·®å¼‚åˆ†æ
    console.log(chalk.blue('ğŸ” Analyzing diff patterns...'));
    const diffAnalysis = await this.analyzeDiffPatterns(diffPng, expectedPng, actualPng, width, height);

    console.log(chalk.green(`âœ… Comparison completed`));
    console.log(chalk.yellow(`ğŸ“Š Match: ${matchPercentage.toFixed(2)}% (${diffPixels}/${totalPixels} pixels differ)`));
    
    // è¾“å‡ºå·®å¼‚åˆ†ææ‘˜è¦
    this.printDiffSummary(diffAnalysis);

    return {
      matchPercentage,
      diffPixels,
      totalPixels,
      dimensions: { width, height },
      analysis: diffAnalysis,
      paths: {
        expected: expectedPath,
        actual: actualPath,
        diff: diffPath
      }
    };
  }

  async analyzeDiffPatterns(diffPng, expectedPng, actualPng, width, height) {
    const analysis = {
      colorRegions: {
        red: { pixels: 0, regions: [], description: 'Significant structural differences' },
        orange: { pixels: 0, regions: [], description: 'Medium-level layout differences' },
        yellow: { pixels: 0, regions: [], description: 'Anti-aliasing/rendering differences' }
      },
      spatialDistribution: {
        border: { pixels: 0, percentage: 0 },
        content: { pixels: 0, percentage: 0 },
        text: { pixels: 0, percentage: 0 }
      },
      diffPatterns: [],
      recommendations: []
    };

    // åˆ†ææ¯ä¸ªåƒç´ çš„å·®å¼‚ç±»å‹å’Œä½ç½®
    const diffRegions = new Map(); // ç”¨äºèšåˆç›¸é‚»çš„å·®å¼‚åƒç´ 
    
    for (let y = 0; y < height; y++) {
      for (let x = 0; x < width; x++) {
        const idx = (width * y + x) << 2;
        const r = diffPng.data[idx];
        const g = diffPng.data[idx + 1];
        const b = diffPng.data[idx + 2];
        
        if (r > 0 || g > 0 || b > 0) { // æœ‰å·®å¼‚çš„åƒç´ 
          // è¯†åˆ«å·®å¼‚é¢œè‰²ç±»å‹
          const colorType = this.identifyDiffColor(r, g, b);
          analysis.colorRegions[colorType].pixels++;
          
          // è¯†åˆ«ç©ºé—´ä½ç½®ç±»å‹
          const spatialType = this.identifySpatialRegion(x, y, width, height);
          analysis.spatialDistribution[spatialType].pixels++;
          
          // èšåˆç›¸é‚»åŒºåŸŸ
          this.aggregateDiffRegion(diffRegions, x, y, colorType, spatialType);
        }
      }
    }

    // å¤„ç†èšåˆçš„å·®å¼‚åŒºåŸŸ
    this.processDiffRegions(diffRegions, analysis);
    
    // è®¡ç®—ç™¾åˆ†æ¯”
    const totalDiffPixels = analysis.colorRegions.red.pixels + 
                           analysis.colorRegions.orange.pixels + 
                           analysis.colorRegions.yellow.pixels;
    
    Object.keys(analysis.spatialDistribution).forEach(key => {
      analysis.spatialDistribution[key].percentage = 
        (analysis.spatialDistribution[key].pixels / totalDiffPixels * 100).toFixed(1);
    });

    // è¯†åˆ«å·®å¼‚æ¨¡å¼
    analysis.diffPatterns = this.identifyDiffPatterns(analysis);
    
    // ç”Ÿæˆä¼˜åŒ–å»ºè®®
    analysis.recommendations = this.generateRecommendations(analysis);

    return analysis;
  }

  identifyDiffColor(r, g, b) {
    // åŸºäº pixelmatch çš„é¢œè‰²é…ç½®è¯†åˆ«å·®å¼‚ç±»å‹
    if (r === 255 && g === 0 && b === 0) {
      return 'red'; // æ˜¾è‘—å·®å¼‚
    } else if (r === 255 && g === 128 && b === 0) {
      return 'orange'; // ä¸­ç­‰å·®å¼‚
    } else if (r === 255 && g === 255 && b === 0) {
      return 'yellow'; // æŠ—é”¯é½¿å·®å¼‚
    } else {
      // å…¶ä»–é¢œè‰²ï¼Œæ ¹æ®ä¸»å¯¼è‰²åˆ†ç±»
      if (r > g && r > b) return 'red';
      if (g > r && g > b) return 'yellow';
      return 'orange';
    }
  }

  identifySpatialRegion(x, y, width, height) {
    const borderThickness = Math.min(width, height) * 0.05; // 5% ä½œä¸ºè¾¹æ¡†åŒºåŸŸ
    
    // è¾¹æ¡†åŒºåŸŸæ£€æµ‹
    if (x < borderThickness || x > width - borderThickness || 
        y < borderThickness || y > height - borderThickness) {
      return 'border';
    }
    
    // æ–‡æœ¬åŒºåŸŸæ£€æµ‹ï¼ˆåŸºäºå¸¸è§çš„æ–‡æœ¬ä½ç½®æ¨¡å¼ï¼‰
    const centerX = width / 2;
    const centerY = height / 2;
    const textRegionWidth = width * 0.6;
    const textRegionHeight = height * 0.3;
    
    if (Math.abs(x - centerX) < textRegionWidth / 2 && 
        Math.abs(y - centerY) < textRegionHeight / 2) {
      return 'text';
    }
    
    return 'content';
  }

  aggregateDiffRegion(diffRegions, x, y, colorType, spatialType) {
    const regionKey = `${Math.floor(x / 10)}_${Math.floor(y / 10)}`; // 10x10 åƒç´ å—
    
    if (!diffRegions.has(regionKey)) {
      diffRegions.set(regionKey, {
        x: Math.floor(x / 10) * 10,
        y: Math.floor(y / 10) * 10,
        width: 10,
        height: 10,
        colorType,
        spatialType,
        pixels: 0
      });
    }
    
    diffRegions.get(regionKey).pixels++;
  }

  processDiffRegions(diffRegions, analysis) {
    for (const region of diffRegions.values()) {
      if (region.pixels > 5) { // åªè®°å½•æœ‰æ„ä¹‰çš„åŒºåŸŸ
        analysis.colorRegions[region.colorType].regions.push({
          x: region.x,
          y: region.y,
          width: region.width,
          height: region.height,
          pixels: region.pixels,
          spatialType: region.spatialType
        });
      }
    }
  }

  identifyDiffPatterns(analysis) {
    const patterns = [];
    
    // è¾¹æ¡†æ¡å¸¦æ¨¡å¼
    if (analysis.spatialDistribution.border.pixels > 0) {
      const borderPercentage = parseFloat(analysis.spatialDistribution.border.percentage);
      if (borderPercentage > 50) {
        patterns.push({
          type: 'border_stripe',
          severity: borderPercentage > 80 ? 'high' : 'medium',
          description: 'Border rendering differences detected',
          affectedArea: `${borderPercentage}% of diff pixels in border region`
        });
      }
    }
    
    // å—çŠ¶å·®å¼‚æ¨¡å¼
    const redRegions = analysis.colorRegions.red.regions;
    if (redRegions.length > 0) {
      const largeBlocks = redRegions.filter(r => r.pixels > 50);
      if (largeBlocks.length > 0) {
        patterns.push({
          type: 'block_difference',
          severity: 'high',
          description: 'Large structural differences detected',
          regions: largeBlocks.length,
          affectedArea: `${largeBlocks.reduce((sum, r) => sum + r.pixels, 0)} pixels`
        });
      }
    }
    
    // æ–‡æœ¬æ¸²æŸ“å·®å¼‚æ¨¡å¼
    if (analysis.spatialDistribution.text.pixels > 0) {
      const textPercentage = parseFloat(analysis.spatialDistribution.text.percentage);
      if (textPercentage > 30) {
        patterns.push({
          type: 'text_rendering',
          severity: 'low',
          description: 'Text rendering differences detected',
          affectedArea: `${textPercentage}% of diff pixels in text region`
        });
      }
    }
    
    return patterns;
  }

  generateRecommendations(analysis) {
    const recommendations = [];
    
    // åŸºäºé¢œè‰²åˆ†å¸ƒçš„å»ºè®®
    const totalDiff = analysis.colorRegions.red.pixels + 
                     analysis.colorRegions.orange.pixels + 
                     analysis.colorRegions.yellow.pixels;
    
    if (analysis.colorRegions.red.pixels / totalDiff > 0.6) {
      recommendations.push({
        priority: 'high',
        category: 'structural',
        action: 'Check layout positioning, element sizing, and border implementation',
        reason: 'High proportion of red pixels indicates structural issues'
      });
    }
    
    if (analysis.spatialDistribution.border.pixels / totalDiff > 0.5) {
      recommendations.push({
        priority: 'high',
        category: 'border',
        action: 'Review strokeAlign implementation and border positioning',
        reason: 'Border region contains majority of differences'
      });
    }
    
    if (analysis.colorRegions.yellow.pixels / totalDiff > 0.4) {
      recommendations.push({
        priority: 'low',
        category: 'rendering',
        action: 'Apply font-smoothing and anti-aliasing optimizations',
        reason: 'High proportion of yellow pixels indicates rendering differences'
      });
    }
    
    return recommendations;
  }

  printDiffSummary(analysis) {
    console.log(chalk.blue('\nğŸ“Š Diff Analysis Summary:'));
    
    // é¢œè‰²åˆ†å¸ƒ
    console.log(chalk.yellow('Color Distribution:'));
    Object.entries(analysis.colorRegions).forEach(([color, data]) => {
      if (data.pixels > 0) {
        console.log(chalk.gray(`  ${color.toUpperCase()}: ${data.pixels} pixels - ${data.description}`));
      }
    });
    
    // ç©ºé—´åˆ†å¸ƒ
    console.log(chalk.yellow('\nSpatial Distribution:'));
    Object.entries(analysis.spatialDistribution).forEach(([region, data]) => {
      if (data.pixels > 0) {
        console.log(chalk.gray(`  ${region}: ${data.pixels} pixels (${data.percentage}%)`));
      }
    });
    
    // è¯†åˆ«çš„æ¨¡å¼
    if (analysis.diffPatterns.length > 0) {
      console.log(chalk.yellow('\nIdentified Patterns:'));
      analysis.diffPatterns.forEach(pattern => {
        const severityColor = pattern.severity === 'high' ? chalk.red : 
                             pattern.severity === 'medium' ? chalk.yellow : chalk.green;
        console.log(severityColor(`  ${pattern.type}: ${pattern.description}`));
      });
    }
    
    // ä¼˜åŒ–å»ºè®®
    if (analysis.recommendations.length > 0) {
      console.log(chalk.yellow('\nRecommendations:'));
      analysis.recommendations.forEach(rec => {
        const priorityColor = rec.priority === 'high' ? chalk.red : 
                             rec.priority === 'medium' ? chalk.yellow : chalk.blue;
        console.log(priorityColor(`  [${rec.priority.toUpperCase()}] ${rec.category}: ${rec.action}`));
      });
    }
  }

  async normalizeImage(actualPath, expectedPath) {
    // Get both image metadata
    const expectedMeta = await sharp(expectedPath).metadata();
    const actualMeta = await sharp(actualPath).metadata();

    console.log(chalk.blue('ğŸ“ Image size analysis:'));
    console.log(chalk.gray(`   Expected: ${expectedMeta.width} Ã— ${expectedMeta.height} pixels`));
    console.log(chalk.gray(`   Actual: ${actualMeta.width} Ã— ${actualMeta.height} pixels`));

    // Check if images are already the same size
    if (expectedMeta.width === actualMeta.width && expectedMeta.height === actualMeta.height) {
      console.log(chalk.green('âœ… Images are already the same size, no normalization needed'));
      return;
    }

    // Calculate scale factors
    const scaleX = actualMeta.width / expectedMeta.width;
    const scaleY = actualMeta.height / expectedMeta.height;

    console.log(chalk.yellow(`âš ï¸  Size mismatch detected:`));
    console.log(chalk.gray(`   Scale factors: X=${scaleX.toFixed(2)}x, Y=${scaleY.toFixed(2)}x`));

    // For 3x scale images, we should resize the expected image to match actual size
    // This preserves the high-resolution actual screenshot for accurate comparison
    if (Math.abs(scaleX - 3) < 0.1 && Math.abs(scaleY - 3) < 0.1) {
      console.log(chalk.blue('ğŸ”„ Detected 3x scale difference, upscaling expected image...'));
      await sharp(expectedPath)
        .resize(actualMeta.width, actualMeta.height, {
          fit: 'fill',
          kernel: sharp.kernel.nearest // Use nearest neighbor to preserve pixel accuracy
        })
        .ensureAlpha()
        .png()
        .toFile(expectedPath + '.tmp');

      await fs.rename(expectedPath + '.tmp', expectedPath);
      console.log(chalk.green('âœ… Expected image upscaled to match actual 3x resolution'));
    } else {
      // For other cases, resize actual to match expected
      console.log(chalk.blue('ğŸ”„ Resizing actual image to match expected size...'));
      await sharp(actualPath)
        .resize(expectedMeta.width, expectedMeta.height, { fit: 'fill' })
        .ensureAlpha()
        .png()
        .toFile(actualPath + '.tmp');

      await fs.rename(actualPath + '.tmp', actualPath);
      console.log(chalk.green('âœ… Actual image resized to match expected size'));
    }
  }




}
