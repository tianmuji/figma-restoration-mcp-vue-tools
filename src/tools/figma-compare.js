import fs from 'fs/promises';
import path from 'path';
import chalk from 'chalk';
import sharp from 'sharp';
import pixelmatch from 'pixelmatch';
import { PNG } from 'pngjs';
import {
  ensureDirectory
} from '../utils/path-config.js';
import { EnhancedRegionAnalyzer } from '../../scripts/enhanced-region-analyzer.js';

export class FigmaCompareTool {
  constructor() {
    this.description = 'Pure Figma component comparison tool: compare existing screenshots and analyze differences with detailed reporting';
    this.inputSchema = {
      type: 'object',
      properties: {
        componentName: {
          type: 'string',
          description: 'Name of the component to compare'
        },
        projectPath: {
          type: 'string',
          default: '/Users/yujie_wu/Documents/work/camscanner-cloud-vue3',
          description: 'Path to the Vue project'
        },
        outputPath: {
          type: 'string',
          description: 'Custom absolute path where comparison results should be saved. If not provided, defaults to component directory'
        },
        threshold: {
          type: 'number',
          default: 0.1,
          description: 'Comparison threshold (0-1, lower is more strict)'
        },
        generateReport: {
          type: 'boolean',
          default: true,
          description: 'Generate detailed analysis report'
        }
      },
      required: ['componentName']
    };
  }

  async execute(args) {
    const {
      componentName,
      projectPath = '/Users/yujie_wu/Documents/work/camscanner-cloud-vue3',
      outputPath, // æ–°å¢ï¼šè‡ªå®šä¹‰è¾“å‡ºè·¯å¾„
      threshold = 0.1,
      generateReport = true
    } = args;

    try {
      console.log(chalk.cyan('ğŸ¯ Figma Component Comparison'));
      console.log(chalk.cyan(`Component: ${componentName}`));
      console.log(chalk.gray('='.repeat(60)));

      // ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„ï¼Œå¦åˆ™ä½¿ç”¨ç»„ä»¶ç›®å½•
      const resultsDir = outputPath || path.join(projectPath, 'src', 'components', componentName);
      console.log(chalk.blue(`ğŸ“ Output directory: ${resultsDir}`));
      await ensureDirectory(resultsDir);

      // Check if actual.png exists
      const actualPath = path.join(resultsDir, 'actual.png');
      try {
        await fs.access(actualPath);
        console.log(chalk.green('âœ… Found existing screenshot: actual.png'));
      } catch (error) {
        throw new Error(`Screenshot not found: ${actualPath}\n\nPlease take a screenshot first using the snapDOM screenshot tool:\n  snapdom_screenshot_vue-figma-tools --componentName ${componentName} --outputPath "${resultsDir}"`);
      }

      // Step 1: Compare images
      console.log(chalk.blue('ğŸ” Comparing images...'));
      const comparisonResult = await this.compareImages({
        componentName,
        resultsDir,
        threshold
      });

      // Step 2: Generate report (if requested)
      let reportPath = null;
      if (generateReport) {
        console.log(chalk.blue('ğŸ“Š Generating analysis report...'));

        // Load region analysis if available
        let regionAnalysisData = null;
        try {
          const regionAnalysisPath = path.join(resultsDir, 'region-analysis.json');
          const regionAnalysisContent = await fs.readFile(regionAnalysisPath, 'utf-8');
          regionAnalysisData = JSON.parse(regionAnalysisContent);
        } catch (error) {
          // Region analysis file not found, continue without it
        }

        reportPath = await this.generateReport({
          componentName,
          resultsDir,
          comparisonResult: {
            ...comparisonResult,
            regionAnalysis: regionAnalysisData
          }
        });
      }

      console.log(chalk.green('âœ… Comparison completed successfully!'));
      console.log(chalk.yellow(`ğŸ“Š Match Percentage: ${comparisonResult.matchPercentage.toFixed(2)}%`));

      // Check if Self-Reflective analysis is needed
      const qualityLevel = this.getQualityLevel(comparisonResult.matchPercentage);
      if (comparisonResult.matchPercentage < 98) {
        console.log(chalk.red('ğŸš¨ è¿˜åŸåº¦æœªè¾¾åˆ°98%æ ‡å‡†ï¼Œéœ€è¦å¯åŠ¨Self-Reflectiveåˆ†æï¼'));
        console.log(chalk.yellow('ğŸ“‹ Self-Reflectiveåˆ†ææµç¨‹ï¼š'));
        console.log(chalk.gray('   1. é‡æ–°æ·±åº¦åˆ†æFigma JSONæ•°æ®'));
        console.log(chalk.gray('   2. éªŒè¯ç´ æå®Œæ•´æ€§å’Œä½ç½®ç²¾ç¡®æ€§'));
        console.log(chalk.gray('   3. æ‰§è¡Œé’ˆå¯¹æ€§ä¿®å¤å’Œè¿­ä»£ä¼˜åŒ–'));
        console.log(chalk.gray('   4. ç›®æ ‡ï¼šè¾¾åˆ°98%+è¿˜åŸåº¦'));
        console.log(chalk.cyan('ğŸ’¡ è¯·æŒ‰ç…§.augment/rules/ä¸­çš„Self-Reflectiveå·¥ä½œæµç¨‹æ‰§è¡Œ'));
      } else {
        console.log(chalk.green('ğŸ‰ æ­å–œï¼å·²è¾¾åˆ°98%è¿˜åŸåº¦æ ‡å‡†ï¼'));
      }

      return {
        success: true,
        componentName,
        comparison: comparisonResult,
        reportPath,
        summary: {
          matchPercentage: comparisonResult.matchPercentage,
          qualityLevel: qualityLevel,
          diffPixels: comparisonResult.diffPixels,
          totalPixels: comparisonResult.totalPixels,
          needsSelfReflective: qualityLevel.needsSelfReflective,
          storagePath: resultsDir, // è¿”å›å®é™…ä½¿ç”¨çš„å­˜å‚¨è·¯å¾„
          customPath: !!outputPath // æ ‡è¯†æ˜¯å¦ä½¿ç”¨äº†è‡ªå®šä¹‰è·¯å¾„
        }
      };

    } catch (error) {
      console.error(chalk.red('âŒ Comparison failed:'), error.message);
      return {
        success: false,
        error: error.message,
        componentName
      };
    }
  }





  async compareImages({ componentName, resultsDir, threshold }) {
    const expectedPath = path.join(resultsDir, 'expected.png');
    const actualPath = path.join(resultsDir, 'actual.png');
    const diffPath = path.join(resultsDir, 'diff.png');

    // Check if expected image exists
    try {
      await fs.access(expectedPath);
    } catch (error) {
      throw new Error(`Expected image not found: ${expectedPath}. Please ensure the Figma design image is downloaded.`);
    }

    // Ensure actual image is in correct format and size
    await this.normalizeImage(actualPath, expectedPath);

    // Load images
    const expectedBuffer = await fs.readFile(expectedPath);
    const actualBuffer = await fs.readFile(actualPath);

    const expectedPng = PNG.sync.read(expectedBuffer);
    const actualPng = PNG.sync.read(actualBuffer);

    const { width, height } = expectedPng;
    const diffPng = new PNG({ width, height });

    // Compare images with optimized settings for 3x scale
    console.log(chalk.blue(`ğŸ” Comparing images at ${width} Ã— ${height} resolution...`));

    const diffPixels = pixelmatch(
      expectedPng.data,
      actualPng.data,
      diffPng.data,
      width,
      height,
      {
        threshold: threshold * 0.8, // Slightly more sensitive for high-res images
        includeAA: true, // Include anti-aliasing for better 3x scale comparison
        alpha: 0.05, // Lower alpha threshold for more precise comparison
        aaColor: [255, 255, 0], // Yellow for anti-aliasing differences
        diffColor: [255, 0, 0], // Red for significant differences
        diffColorAlt: [255, 128, 0] // Orange for alternative differences
      }
    );

    // Save diff image
    await fs.writeFile(diffPath, PNG.sync.write(diffPng));

    const totalPixels = width * height;
    const matchPercentage = ((totalPixels - diffPixels) / totalPixels) * 100;

    console.log(chalk.green(`âœ… Comparison completed`));
    console.log(chalk.yellow(`ğŸ“Š Match: ${matchPercentage.toFixed(2)}% (${diffPixels}/${totalPixels} pixels differ)`));

    // Enhanced region analysis
    console.log(chalk.blue('ğŸ” Performing enhanced region analysis...'));
    let regionAnalysis = null;
    try {
      const analyzer = new EnhancedRegionAnalyzer();

      // Try to load Figma data for semantic analysis
      let figmaData = null;
      try {
        const figmaDataPath = path.join(resultsDir, 'figma-data.json');
        const figmaDataContent = await fs.readFile(figmaDataPath, 'utf-8');
        figmaData = JSON.parse(figmaDataContent);
        console.log(chalk.gray('ğŸ“‹ Figma data loaded for semantic analysis'));
      } catch (error) {
        console.log(chalk.yellow('âš ï¸  No Figma data found for semantic analysis'));
      }

      regionAnalysis = await analyzer.analyzeRegionDifferences(expectedPath, actualPath, figmaData);
      console.log(chalk.green(`âœ… Region analysis completed: ${regionAnalysis.regions.length} difference regions identified`));

      // Save detailed region analysis
      const regionAnalysisPath = path.join(resultsDir, 'region-analysis.json');
      await fs.writeFile(regionAnalysisPath, JSON.stringify(regionAnalysis, null, 2));
      console.log(chalk.gray(`ğŸ’¾ Region analysis saved: ${regionAnalysisPath}`));

    } catch (error) {
      console.log(chalk.yellow(`âš ï¸  Region analysis failed: ${error.message}`));
      console.log(chalk.gray(`Error details: ${error.stack}`));
    }

    return {
      matchPercentage,
      diffPixels,
      totalPixels,
      dimensions: { width, height },
      paths: {
        expected: expectedPath,
        actual: actualPath,
        diff: diffPath
      },
      regionAnalysis
    };
  }

  async normalizeImage(actualPath, expectedPath) {
    // Get both image metadata
    const expectedMeta = await sharp(expectedPath).metadata();
    const actualMeta = await sharp(actualPath).metadata();

    console.log(chalk.blue('ğŸ“ Image size analysis:'));
    console.log(chalk.gray(`   Expected: ${expectedMeta.width} Ã— ${expectedMeta.height} pixels`));
    console.log(chalk.gray(`   Actual: ${actualMeta.width} Ã— ${actualMeta.height} pixels`));

    // Check if images are already the same size
    if (expectedMeta.width === actualMeta.width && expectedMeta.height === actualMeta.height) {
      console.log(chalk.green('âœ… Images are already the same size, no normalization needed'));
      return;
    }

    // Calculate scale factors
    const scaleX = actualMeta.width / expectedMeta.width;
    const scaleY = actualMeta.height / expectedMeta.height;

    console.log(chalk.yellow(`âš ï¸  Size mismatch detected:`));
    console.log(chalk.gray(`   Scale factors: X=${scaleX.toFixed(2)}x, Y=${scaleY.toFixed(2)}x`));

    // For 3x scale images, we should resize the expected image to match actual size
    // This preserves the high-resolution actual screenshot for accurate comparison
    if (Math.abs(scaleX - 3) < 0.1 && Math.abs(scaleY - 3) < 0.1) {
      console.log(chalk.blue('ğŸ”„ Detected 3x scale difference, upscaling expected image...'));
      await sharp(expectedPath)
        .resize(actualMeta.width, actualMeta.height, {
          fit: 'fill',
          kernel: sharp.kernel.nearest // Use nearest neighbor to preserve pixel accuracy
        })
        .ensureAlpha()
        .png()
        .toFile(expectedPath + '.tmp');

      await fs.rename(expectedPath + '.tmp', expectedPath);
      console.log(chalk.green('âœ… Expected image upscaled to match actual 3x resolution'));
    } else {
      // For other cases, resize actual to match expected
      console.log(chalk.blue('ğŸ”„ Resizing actual image to match expected size...'));
      await sharp(actualPath)
        .resize(expectedMeta.width, expectedMeta.height, { fit: 'fill' })
        .ensureAlpha()
        .png()
        .toFile(actualPath + '.tmp');

      await fs.rename(actualPath + '.tmp', actualPath);
      console.log(chalk.green('âœ… Actual image resized to match expected size'));
    }
  }

  async generateReport({ componentName, resultsDir, comparisonResult }) {
    const reportData = {
      componentName,
      timestamp: new Date().toISOString(),
      comparison: {
        ...comparisonResult,
        qualityLevel: this.getQualityLevel(comparisonResult.matchPercentage)
      },
      regionAnalysis: comparisonResult.regionAnalysis || null,
      summary: {
        status: this.getQualityLevel(comparisonResult.matchPercentage),
        recommendation: this.getRecommendation(comparisonResult.matchPercentage, comparisonResult.regionAnalysis),
        nextSteps: this.getNextSteps(comparisonResult.matchPercentage, comparisonResult.regionAnalysis)
      }
    };

    // Save JSON report
    const jsonReportPath = path.join(resultsDir, 'figma-analysis-report.json');
    await fs.writeFile(jsonReportPath, JSON.stringify(reportData, null, 2));

    // Generate Markdown report
    const markdownReport = this.generateMarkdownReport(reportData);
    const mdReportPath = path.join(resultsDir, 'figma-analysis-report.md');
    await fs.writeFile(mdReportPath, markdownReport);

    console.log(chalk.green(`âœ… Reports generated:`));
    console.log(chalk.gray(`   JSON: ${jsonReportPath}`));
    console.log(chalk.gray(`   Markdown: ${mdReportPath}`));

    return {
      json: jsonReportPath,
      markdown: mdReportPath,
      data: reportData
    };
  }

  generateMarkdownReport(data) {
    const { componentName, comparison, summary, regionAnalysis } = data;
    const { qualityLevel } = comparison;

    let regionSection = '';
    if (regionAnalysis && regionAnalysis.regions && regionAnalysis.regions.length > 0) {
      regionSection = `
## ğŸ” åŒºåŸŸå·®å¼‚åˆ†æ

**å‘ç°å·®å¼‚åŒºåŸŸ**: ${regionAnalysis.regions.length} ä¸ª
**è¯­ä¹‰åˆ†æè´¨é‡**: ${regionAnalysis.semanticAnalysis?.summary?.analysisQuality || 'N/A'}

### ä¸»è¦å·®å¼‚åŒºåŸŸ

${regionAnalysis.regions.slice(0, 5).map((region, index) => `
#### åŒºåŸŸ ${index + 1} (${region.id})
- **ä½ç½®**: (${region.center.x}, ${region.center.y})
- **å¤§å°**: ${region.boundingBox.width} Ã— ${region.boundingBox.height} (${region.area} åƒç´ )
- **ç±»å‹**: ${this.getRegionTypeDescription(region.regionType)}
- **ä¸¥é‡ç¨‹åº¦**: ${this.getSeverityDescription(region.severity)}
${region.semanticInfo?.matchedElements?.length > 0 ?
  `- **åŒ¹é…çš„Figmaå…ƒç´ **: ${region.semanticInfo.matchedElements[0].nodeName} (${region.semanticInfo.matchedElements[0].nodeType})` :
  '- **åŒ¹é…çš„Figmaå…ƒç´ **: æœªæ‰¾åˆ°åŒ¹é…å…ƒç´ '
}
${region.semanticInfo?.possibleIssues?.length > 0 ?
  `- **å¯èƒ½é—®é¢˜**: ${region.semanticInfo.possibleIssues[0].description}` :
  ''
}
`).join('')}

### ä¼˜åŒ–å»ºè®®

${regionAnalysis.recommendations?.map(rec => `
**${rec.type}** (ä¼˜å…ˆçº§: ${rec.priority})
- ${rec.description}
${rec.regions ? `- æ¶‰åŠåŒºåŸŸ: ${rec.regions.join(', ')}` : ''}
`).join('') || 'æš‚æ— ç‰¹å®šå»ºè®®'}
`;
    }

    return `# Figmaç»„ä»¶è¿˜åŸåˆ†ææŠ¥å‘Š - ${componentName}

## ğŸ“Š è¿˜åŸåº¦è¯„ä¼°

**è¿˜åŸåº¦**: ${comparison.matchPercentage.toFixed(2)}% ${qualityLevel.emoji}
**è´¨é‡ç­‰çº§**: ${qualityLevel.text}
**å·®å¼‚åƒç´ **: ${comparison.diffPixels.toLocaleString()} / ${comparison.totalPixels.toLocaleString()}
**å›¾ç‰‡å°ºå¯¸**: ${comparison.dimensions.width} Ã— ${comparison.dimensions.height}

## ğŸ¯ è´¨é‡åˆ†æ

${this.getQualityAnalysis(comparison.matchPercentage)}
${regionSection}
## ğŸ“ æ–‡ä»¶è·¯å¾„

- **é¢„æœŸå›¾ç‰‡**: \`${path.basename(comparison.paths.expected)}\`
- **å®é™…æˆªå›¾**: \`${path.basename(comparison.paths.actual)}\`
- **å·®å¼‚å›¾ç‰‡**: \`${path.basename(comparison.paths.diff)}\`
${regionAnalysis ? `- **åŒºåŸŸåˆ†æ**: \`region-analysis.json\`` : ''}

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

${summary.recommendation}

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

${summary.nextSteps.map(step => `- ${step}`).join('\n')}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: ${new Date(data.timestamp).toLocaleString('zh-CN')}*
`;
  }

  getQualityAnalysis(percentage) {
    if (percentage >= 97) {
      return 'ğŸ¯ **ä¼˜ç§€è¿˜åŸ** - è¾¾åˆ°åƒç´ çº§ç²¾ç¡®è¿˜åŸï¼Œå¯ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚';
    } else if (percentage >= 95) {
      return 'âœ… **è‰¯å¥½è¿˜åŸ** - é«˜è´¨é‡è¿˜åŸï¼Œç»†èŠ‚å¤„ç†åˆ°ä½ï¼Œé€‚åˆç”Ÿäº§ä½¿ç”¨ã€‚';
    } else if (percentage >= 90) {
      return 'âš ï¸ **éœ€è¦æ”¹è¿›** - åŸºæœ¬ç»“æ„æ­£ç¡®ï¼Œä½†å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼Œå»ºè®®ç»§ç»­ä¼˜åŒ–ã€‚';
    } else if (percentage >= 85) {
      return 'âŒ **è¾ƒå·®è¿˜åŸ** - å­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼Œéœ€è¦é‡ç‚¹æ£€æŸ¥å¸ƒå±€å’Œæ ·å¼ã€‚';
    } else {
      return 'ğŸ’¥ **è¿˜åŸå¤±è´¥** - å·®å¼‚è¿‡å¤§ï¼Œå»ºè®®é‡æ–°åˆ†æè®¾è®¡ç¨¿å’Œå®ç°æ–¹æ¡ˆã€‚';
    }
  }

  getRecommendation(percentage, regionAnalysis = null) {
    let baseRecommendation = '';
    if (percentage >= 98) {
      baseRecommendation = 'ğŸ‰ æ­å–œï¼å·²è¾¾åˆ°åƒç´ çº§ç²¾ç¡®è¿˜åŸæ ‡å‡†ï¼Œå¯ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚';
    } else if (percentage < 98) {
      baseRecommendation = 'ğŸ”„ **è§¦å‘Self-Reflectiveåˆ†æ** - è¿˜åŸåº¦æœªè¾¾åˆ°98%æ ‡å‡†ï¼Œéœ€è¦å¯åŠ¨è‡ªåŠ¨é‡æ–°åˆ†ææµç¨‹ï¼š\n' +
        '1. é‡æ–°æ·±åº¦åˆ†æFigma JSONæ•°æ®\n' +
        '2. éªŒè¯ç´ æå®Œæ•´æ€§å’Œä½ç½®ç²¾ç¡®æ€§\n' +
        '3. æ‰§è¡Œé’ˆå¯¹æ€§ä¿®å¤å’Œè¿­ä»£ä¼˜åŒ–\n' +
        '4. ç›®æ ‡ï¼šè¾¾åˆ°98%+è¿˜åŸåº¦';
    } else if (percentage >= 95) {
      baseRecommendation = 'å½“å‰è¿˜åŸè´¨é‡å·²è¾¾åˆ°é«˜æ ‡å‡†ï¼Œä½†éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥è¾¾åˆ°98%ç›®æ ‡ã€‚';
    } else if (percentage >= 90) {
      baseRecommendation = 'ç»§ç»­ä¼˜åŒ–å¸ƒå±€å’Œæ ·å¼ç»†èŠ‚ï¼Œé‡ç‚¹å…³æ³¨å·®å¼‚è¾ƒå¤§çš„åŒºåŸŸã€‚';
    } else if (percentage >= 85) {
      baseRecommendation = 'éœ€è¦ç³»ç»Ÿæ€§æ£€æŸ¥å¸ƒå±€ç»“æ„ã€ç´ æä½¿ç”¨å’Œæ ·å¼å®ç°ã€‚';
    } else {
      baseRecommendation = 'å»ºè®®é‡æ–°åˆ†æFigmaè®¾è®¡ç¨¿ï¼Œæ£€æŸ¥ç´ æä¸‹è½½å’ŒåŸºç¡€å¸ƒå±€å®ç°ã€‚';
    }

    // å¦‚æœæœ‰åŒºåŸŸåˆ†ææ•°æ®ï¼Œæ·»åŠ å…·ä½“å»ºè®®
    if (regionAnalysis && regionAnalysis.recommendations && regionAnalysis.recommendations.length > 0) {
      const topRecommendation = regionAnalysis.recommendations[0];
      baseRecommendation += ` é‡ç‚¹å…³æ³¨ï¼š${topRecommendation.description}`;
    }

    return baseRecommendation;
  }

  getNextSteps(percentage, regionAnalysis = null) {
    let baseSteps = [];
    if (percentage >= 98) {
      baseSteps = [
        'âœ… è¿˜åŸåº¦å·²è¾¾æ ‡ï¼Œè¿›è¡Œæœ€ç»ˆéªŒæ”¶',
        'ğŸ“ å®Œå–„ç»„ä»¶æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜',
        'ğŸš€ å‡†å¤‡å‘å¸ƒåˆ°ç”Ÿäº§ç¯å¢ƒ'
      ];
    } else if (percentage < 98) {
      baseSteps = [
        'ğŸ”„ **ç«‹å³å¯åŠ¨Self-Reflectiveåˆ†ææµç¨‹**',
        'ğŸ“Š é‡æ–°è·å–å’Œæ·±åº¦åˆ†æFigma JSONæ•°æ®',
        'ğŸ¨ éªŒè¯æ‰€æœ‰ç´ æå®Œæ•´æ€§å’Œæ­£ç¡®æ€§',
        'ğŸ“ é‡æ–°è®¡ç®—å…ƒç´ ä½ç½®å’Œå¸ƒå±€ç²¾ç¡®æ€§',
        'ğŸ”§ æ‰§è¡Œé’ˆå¯¹æ€§ä¿®å¤å’Œä¼˜åŒ–',
        'ğŸ¯ ç›®æ ‡ï¼šè¾¾åˆ°98%+è¿˜åŸåº¦'
      ];
    } else if (percentage >= 95) {
      baseSteps = [
        'ğŸ” åˆ†æå‰©ä½™å·®å¼‚åŒºåŸŸ',
        'âš¡ è¿›è¡Œç²¾ç»†åŒ–è°ƒä¼˜',
        'ğŸ“ˆ æå‡è‡³98%ç›®æ ‡è¿˜åŸåº¦'
      ];
    } else if (percentage >= 90) {
      baseSteps = [
        'åˆ†æå·®å¼‚å›¾ç‰‡ï¼Œå®šä½å…·ä½“é—®é¢˜åŒºåŸŸ',
        'ä¼˜åŒ–å¸ƒå±€å’Œæ ·å¼å®ç°',
        'é‡æ–°æµ‹è¯•å¹¶å¯¹æ¯”'
      ];
    } else if (percentage >= 85) {
      baseSteps = [
        'æ£€æŸ¥ç´ ææ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸‹è½½å’Œä½¿ç”¨',
        'éªŒè¯å¸ƒå±€ç»“æ„å’ŒCSSå®ç°',
        'å¯¹æ¯”Figmaè®¾è®¡ç¨¿é‡æ–°è°ƒæ•´'
      ];
    } else {
      baseSteps = [
        'é‡æ–°åˆ†æFigmaè®¾è®¡ç¨¿ç»“æ„',
        'ç¡®è®¤æ‰€æœ‰ç´ æå·²æ­£ç¡®ä¸‹è½½',
        'é‡æ–°å®ç°åŸºç¡€å¸ƒå±€å’Œæ ·å¼'
      ];
    }

    // å¦‚æœæœ‰åŒºåŸŸåˆ†ææ•°æ®ï¼Œæ·»åŠ å…·ä½“æ­¥éª¤
    if (regionAnalysis && regionAnalysis.recommendations) {
      const criticalRecs = regionAnalysis.recommendations.filter(rec => rec.priority === 'high');
      if (criticalRecs.length > 0) {
        baseSteps.unshift(`ä¼˜å…ˆå¤„ç†ï¼š${criticalRecs[0].description}`);
      }
    }

    return baseSteps;
  }

  getRegionTypeDescription(regionType) {
    const descriptions = {
      'small_detail': 'å°ç»†èŠ‚å·®å¼‚',
      'large_area': 'å¤§é¢ç§¯å·®å¼‚',
      'horizontal_element': 'æ°´å¹³å…ƒç´ å·®å¼‚',
      'vertical_element': 'å‚ç›´å…ƒç´ å·®å¼‚',
      'color_mismatch': 'é¢œè‰²ä¸åŒ¹é…',
      'general_difference': 'ä¸€èˆ¬å·®å¼‚'
    };
    return descriptions[regionType] || regionType;
  }

  getSeverityDescription(severity) {
    const descriptions = {
      'critical': 'ğŸ”´ ä¸¥é‡',
      'major': 'ğŸŸ  é‡è¦',
      'minor': 'ğŸŸ¡ è½»å¾®',
      'trivial': 'ğŸŸ¢ å¾®å°'
    };
    return descriptions[severity] || severity;
  }

  getQualityLevel(percentage) {
    if (percentage >= 98) return { level: 'perfect', emoji: 'ğŸ¯', text: 'å®Œç¾', needsSelfReflective: false };
    if (percentage >= 95) return { level: 'excellent', emoji: 'âœ¨', text: 'ä¼˜ç§€', needsSelfReflective: true };
    if (percentage >= 90) return { level: 'good', emoji: 'âœ…', text: 'è‰¯å¥½', needsSelfReflective: true };
    if (percentage >= 85) return { level: 'needs_improvement', emoji: 'âš ï¸', text: 'éœ€è¦æ”¹è¿›', needsSelfReflective: true };
    if (percentage >= 80) return { level: 'poor', emoji: 'âŒ', text: 'è¾ƒå·®', needsSelfReflective: true };
    return { level: 'failed', emoji: 'ğŸ’¥', text: 'å¤±è´¥', needsSelfReflective: true };
  }
}
